{"cells": [{"metadata": {}, "cell_type": "code", "source": "#Importing Basic Libraries\nimport pandas as pd\nimport numpy as np", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Basic Command\nprint(\"Hello Capstone Project Course\")", "execution_count": 3, "outputs": [{"output_type": "stream", "text": "Hello Capstone Project Course\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "#Week 1: Problem Description & Background- Introduction and Business Understanding\n\n##Introduction and Project Aims\nAccording to online sources, the USA experiences an average of approximately 102 vehicle crashes per day. From approximately 6 million crashes a year, over 35,000 crashes are fatal.\nTo imporve the country's road safety, it is important to understand the the causes of accidents as well as the conditions leading to the incident.\n\nMoreover, understanding the factors prior to the incidents through graphical and statistical analysis, including the level of severity, liklihood of collisions, and probaility of injury; can\nfurther improve the education sector within road safety as well as give governmental bodies the data needed to build safer roads and raise awareness of the main factors and conditions leading to road incidents.\n\nThe aim of this project is to use publicly available data- published by the Seattle Deport of Transportation (SDOT) in the form of a dataset, to indentify the relevant information that allow for the comprehension\non the number, injuries, and severity of collision occur in Seattle.\n\nThe data will be analysed mathematically and graphically through data science methodologies such as data visualisation tools and machine learning models in order to provide insight on traffic collisions in Seattle.\n\n##Data Understanding\nThe data used througout this project is extracted from the SDOT's website entitled \"Collisions-All Years\". This dataset includes all types of collisions, whether be vehicle, bicycle or pedestrian, filed by the\nSeattle Police Department. \n\nThe dataset provided includes 65,000 collisions from 2004 to present day, updated on a weekly basis. The severity is also an important factor that is incorporated within the collisions dataset with 5 codes, explained:\n- 0: unknown\n- 1: property damage\n- 2: injury\n- 2b: serious injury\n- 3: fatality\n\nThe actual dataset only includes codes 1 and 2 without the inclusion of any other alternatives; but gives 37 attributes related to the collisions reported such as day, time, month, weather etc. All of which will be used \nto build our model and explain trends related to traffic collisions.\n\nThe full description of the data can be found at: https://s3.us.cloud-object-storage.appdomain.cloud/cf-courses-data/CognitiveClass/DP0701EN/version-2/Metadata.pdf\n\n\n"}, {"metadata": {}, "cell_type": "code", "source": "#Week 2: Project Deliverables\n###Importing Required Libraries & Tools\n\nimport pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plot\nfrom sklearn import preprocessing\nfrom sklearn.metrics import jaccard_similarity_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import log_loss\n\n\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom matplotlib.ticker import NullFormatter\nimport matplotlib.ticker as ticker\nfrom sklearn import preprocessing\n%matplotlib inline\nfrom sklearn.utils import resample\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.metrics import accuracy_score\nimport seaborn as sns\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.image as mpimg\nfrom sklearn import tree\nfrom sklearn.tree import export_graphviz\nfrom sklearn import svm\nfrom sklearn.ensemble import RandomForestClassifier\nimport matplotlib as mpl", "execution_count": 4, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "### Importing Dataset\n", "execution_count": 8, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}